{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input the direction of TEST DATA (if need to use the default file, type 'DEFAULT'): E:\\SHU\\10901\\AI Introduction\\Final project\\input\\coustomDIR\n",
      "E:\\SHU\\10901\\AI Introduction\\Final project\\input\\coustomDIR\n"
     ]
    }
   ],
   "source": [
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np         # dealing with arrays\n",
    "import os                  # dealing with directories\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm      # a nice pretty percentage bar for tasks.\n",
    "\n",
    "TRAIN_DIR = r'E:\\SHU\\10901\\AI Introduction\\Final project\\input\\Kaggle_Data\\train'\n",
    "\n",
    "TEST_DIR = input(\"Please input the direction of TEST DATA (if need to use the default file, type 'DEFAULT'): \")\n",
    "\n",
    "if TEST_DIR == 'DEFAULT':\n",
    "    TEST_DIR = r'E:\\SHU\\10901\\AI Introduction\\Final project\\input\\Kaggle_Data\\test' \n",
    "else:\n",
    "    TEST_DIR = TEST_DIR\n",
    "    \n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'animals_recognize-{}-{}.model'.format(LR, '2conv-basic') # just so we remember which saved model is which, sizes must match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    if word_label == 'cat': return          [1,0,0,0,0,0,0,0,0,0]\n",
    "    elif word_label == 'dog': return        [0,1,0,0,0,0,0,0,0,0]\n",
    "    elif word_label == 'Horse': return      [0,0,1,0,0,0,0,0,0,0]\n",
    "    elif word_label == 'Chicken': return    [0,0,0,1,0,0,0,0,0,0]\n",
    "    elif word_label == 'Cow': return        [0,0,0,0,1,0,0,0,0,0]\n",
    "    elif word_label == 'Elefante': return   [0,0,0,0,0,1,0,0,0,0]\n",
    "    elif word_label == 'Butterfly': return  [0,0,0,0,0,0,1,0,0,0]\n",
    "    elif word_label == 'Sheep': return      [0,0,0,0,0,0,0,1,0,0]\n",
    "    elif word_label == 'Spyder': return     [0,0,0,0,0,0,0,0,1,0]\n",
    "    elif word_label == 'Squirrel': return   [0,0,0,0,0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "        \n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = create_train_data()\n",
    "# If you have already created the dataset:\n",
    "train_data = np.load('train_data.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:538: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\User\\code\\animals_recognize-0.001-2conv-basic.model\n",
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-1000]\n",
    "test = train_data[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 25084  | total loss: \u001b[1m\u001b[32m0.42302\u001b[0m\u001b[0m | time: 58.253s\n",
      "| Adam | epoch: 003 | loss: 0.42302 - acc: 0.8630 -- iter: 43584/43648\n",
      "Training Step: 25085  | total loss: \u001b[1m\u001b[32m0.41461\u001b[0m\u001b[0m | time: 59.333s\n",
      "| Adam | epoch: 003 | loss: 0.41461 - acc: 0.8642 | val_loss: 0.49608 - val_acc: 0.8280 -- iter: 43648/43648\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\User\\code\\animals_recognize-0.001-2conv-basic.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 83.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if you need to create the data:\n",
    "test_data = process_test_data()\n",
    "# if you already have some saved:\n",
    "# test_data = np.load('test_data.npy', allow_pickle=True)\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "for num,data in enumerate(test_data[:12]):\n",
    "    \n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(3,4,num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 0: str_label='Cat'\n",
    "    elif np.argmax(model_out) == 1: str_label='Dog'\n",
    "    elif np.argmax(model_out) == 2: str_label='Horse'\n",
    "    elif np.argmax(model_out) == 3: str_label='Chicken'\n",
    "    elif np.argmax(model_out) == 4: str_label='Cow'\n",
    "    elif np.argmax(model_out) == 5: str_label='Elefante'\n",
    "    elif np.argmax(model_out) == 6: str_label='Butterfly'\n",
    "    elif np.argmax(model_out) == 7: str_label='Sheep'\n",
    "    elif np.argmax(model_out) == 8: str_label='Spyder'\n",
    "    elif np.argmax(model_out) == 9: str_label='Squirrel'\n",
    "        \n",
    "    y.imshow(orig,cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 32148/32148 [00:35<00:00, 901.48it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "            \n",
    "with open('submission_file.csv','a') as f:\n",
    "    for data in tqdm(test_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
